{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename (a.csv)\n",
      "Create new csv file\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import csv\n",
    "from csv import reader\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re, string , time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "    \n",
    "#function to clean the raw texts    \n",
    "def cleantext(rawtext):\n",
    "\n",
    "    #####change into lower case####\n",
    "    lowertext=rawtext.lower()\n",
    "    #####remove encoded b from text because after reading it become string instead of byte object####\n",
    "    lowertext= re.sub(r'^b','', lowertext)\n",
    "    lowertext= re.sub(r'^\"rt','', lowertext)\n",
    "    lowertext= re.sub(r'^\\'rt','', lowertext)\n",
    "    ##### remove https links####\n",
    "    lowertext = re.sub(r'https?:\\/\\/.*[\\r\\n]*','', lowertext)\n",
    "    ##### remove words starts with @ #######\n",
    "    lowertext = re.sub(r'@.*?(?=\\s)','', lowertext)\n",
    "    ##### remove words starts with '#' ######\n",
    "    lowertext = re.sub(r'#.*?(?=\\s)','', lowertext)\n",
    "    #####tokenize the words######\n",
    "    tokenizedtext=word_tokenize(lowertext)\n",
    "\n",
    "    \n",
    "    #punctutation first because emojis\n",
    "    ##### remove punctuation from each word####\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    removedpunctuation = [w.translate(table) for w in tokenizedtext]\n",
    "\n",
    "    ##### remove remaining tokens that are not alphabetic####\n",
    "    strippedwords = [word for word in removedpunctuation if word.isalpha()]\n",
    "    \n",
    "    \n",
    "    #########remove extra words###########\n",
    "    removedword=[re.sub(r'(.)\\1{2,}',r'\\1\\1',w) for w in strippedwords ]\n",
    "    \n",
    "    lemmatizedword=[WordNetLemmatizer().lemmatize(w) for w in removedword]    \n",
    "            \n",
    "    finaltext=\" \".join(lemmatizedword)\n",
    "    return finaltext\n",
    "\n",
    "#####function to insert cleaned data into the rows ####\n",
    "def insertrow(label,rawtext,csvWriter):\n",
    "    \n",
    "    finaltext=cleantext(rawtext)\n",
    "    if not finaltext==\"\":\n",
    "        csvWriter.writerow([label, finaltext,rawtext])\n",
    "\n",
    "#####function to read raw data file####\n",
    "def readrawfile(csvWriter):\n",
    "    # skip first line i.e. read header first and then iterate over each row od csv as a list\n",
    "    with open('dataset.csv', 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "    # Check file as empty\n",
    "        if header != None:\n",
    "        # Iterate over each row after the header in the csv\n",
    "            for row in csv_reader:\n",
    "    # row variable is a list that represents a row in csv\n",
    "                insertrow(row[0],row[1],csvWriter)\n",
    "        \n",
    "#####function to create new csv file####        \n",
    "def createcsv():\n",
    "    filename=\"a.csv\"\n",
    "    print(\"Filename (\"+filename +\")\")\n",
    "\n",
    "    if not path.exists(filename):\n",
    "        ####Open/Create a file to append data###########\n",
    "        csvFile = open(filename ,'a',newline=\"\")\n",
    "        #####Use csv Writer#################\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        csvWriter.writerow([\"Emotion\",\"Content\",\"Original Content\"])\n",
    "        print('Create new csv file')\n",
    "    else:\n",
    "        ####Open/Create a file to append data###########\n",
    "        csvFile = open(filename ,'a',newline=\"\")\n",
    "        #####Use csv Writer#################\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        print('Found previous csv file')\n",
    "    readrawfile(csvWriter)\n",
    "\n",
    "def main():  \n",
    "    createcsv()\n",
    "\n",
    "\n",
    "##### Standard boilerplate to call the main() function to begin\n",
    "##### the program.\n",
    "if __name__== \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
